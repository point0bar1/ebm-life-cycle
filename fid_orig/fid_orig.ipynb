{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19777,"status":"ok","timestamp":1634146188853,"user":{"displayName":"MITCHELL HILL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00701271769183393256"},"user_tz":240},"id":"sykZ83w6yAPJ","outputId":"48753dd1-2ffc-44e2-d644-7b9670046b7f"},"outputs":[],"source":["#####################\n","# ## COLAB SETUP ## #\n","#####################\n","\n","# set to True if running on colab to connect google drive, otherwise set to False\n","USE_COLAB = True\n","\n","if USE_COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1634146188854,"user":{"displayName":"MITCHELL HILL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00701271769183393256"},"user_tz":240},"id":"bjo9C_4axzSJ"},"outputs":[],"source":["####################\n","# ## PARAMETERS ## #\n","####################\n","\n","config = {\n","  # paths to saved images\n","  \"path_1\": '',  # path to image bank 1 output from fid_save_ims.ipynb\n","  \"path_2\": ''  # path to image bank 2 output from fid_save_ims.ipynb\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1634146189038,"user":{"displayName":"MITCHELL HILL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00701271769183393256"},"user_tz":240},"id":"CvhK5IrVr01X","outputId":"dadba4ac-e218-4c9a-85f1-90963fda807e"},"outputs":[],"source":["%tensorflow_version 1.x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":449729,"status":"ok","timestamp":1634146638763,"user":{"displayName":"MITCHELL HILL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00701271769183393256"},"user_tz":240},"id":"Z6K4-XW-xgXz","outputId":"9b82ae0d-cff7-49bb-d85e-be216d4acb61"},"outputs":[],"source":["#!/usr/bin/env python3\n","''' Calculates the Frechet Inception Distance (FID) to evalulate GANs.\n","The FID metric calculates the distance between two distributions of images.\n","Typically, we have summary statistics (mean & covariance matrix) of one\n","of these distributions, while the 2nd distribution is given by a GAN.\n","When run as a stand-alone program, it compares the distribution of\n","images that are stored as PNG/JPEG at a specified location with a\n","distribution given by summary statistics (in pickle format).\n","The FID is calculated by assuming that X_1 and X_2 are the activations of\n","the pool_3 layer of the inception net for generated samples and real world\n","samples respectivly.\n","See --help to see further details.\n","'''\n","\n","from __future__ import absolute_import, division, print_function\n","import numpy as np\n","import os\n","from pathlib import Path\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","import gzip, pickle\n","import tensorflow as tf\n","from imageio import imread\n","from scipy import linalg\n","import pathlib\n","import urllib\n","import warnings\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","\n","class InvalidFIDException(Exception):\n","    pass\n","\n","\n","###########################\n","# ## ORIGINAL FID CODE ## #\n","###########################\n","\n","def create_inception_graph(pth):\n","    \"\"\"Creates a graph from saved GraphDef file.\"\"\"\n","    # Creates graph from saved graph_def.pb.\n","    with tf.io.gfile.GFile( pth, 'rb') as f:\n","        graph_def = tf.compat.v1.GraphDef()\n","        graph_def.ParseFromString( f.read())\n","        _ = tf.import_graph_def( graph_def, name='FID_Inception_Net')\n","#-------------------------------------------------------------------------------\n","\n","\n","# code for handling inception net derived from\n","#   https://github.com/openai/improved-gan/blob/master/inception_score/model.py\n","def _get_inception_layer(sess):\n","    \"\"\"Prepares inception net for batched usage and returns pool_3 layer. \"\"\"\n","    layername = 'FID_Inception_Net/pool_3:0'\n","    pool3 = sess.graph.get_tensor_by_name(layername)\n","    ops = pool3.graph.get_operations()\n","    for op_idx, op in enumerate(ops):\n","        for o in op.outputs:\n","            shape = o.get_shape()\n","            if shape._dims is not None:\n","              #shape = [s.value for s in shape] TF 1.x\n","              shape = [s for s in shape] #TF 2.x\n","              new_shape = []\n","              for j, s in enumerate(shape):\n","                if s == 1 and j == 0:\n","                  new_shape.append(None)\n","                else:\n","                  new_shape.append(s)\n","              o.__dict__['_shape_val'] = tf.TensorShape(new_shape)\n","    return pool3\n","#-------------------------------------------------------------------------------\n","\n","\n","def get_activations(images, sess, batch_size=50, verbose=False):\n","    \"\"\"Calculates the activations of the pool_3 layer for all images.\n","    Params:\n","    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n","                     must lie between 0 and 256.\n","    -- sess        : current session\n","    -- batch_size  : the images numpy array is split into batches with batch size\n","                     batch_size. A reasonable batch size depends on the disposable hardware.\n","    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n","                     batches is reported.\n","    Returns:\n","    -- A numpy array of dimension (num images, 2048) that contains the\n","       activations of the given tensor when feeding inception with the query tensor.\n","    \"\"\"\n","    inception_layer = _get_inception_layer(sess)\n","    n_images = images.shape[0]\n","    if batch_size > n_images:\n","        print(\"warning: batch size is bigger than the data size. setting batch size to data size\")\n","        batch_size = n_images\n","    n_batches = n_images//batch_size # drops the last batch if < batch_size\n","    pred_arr = np.empty((n_batches * batch_size,2048))\n","    for i in range(n_batches):\n","        if verbose:\n","            print(\"\\rPropagating batch %d/%d\" % (i+1, n_batches), end=\"\", flush=True)\n","        start = i*batch_size\n","        \n","        if start+batch_size < n_images:\n","            end = start+batch_size\n","        else:\n","            end = n_images\n","        \n","        batch = images[start:end]\n","        pred = sess.run(inception_layer, {'FID_Inception_Net/ExpandDims:0': batch})\n","        pred_arr[start:end] = pred.reshape(batch.shape[0],-1)\n","    if verbose:\n","        print(\" done\")\n","    return pred_arr\n","#-------------------------------------------------------------------------------\n","\n","\n","def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n","    \"\"\"Numpy implementation of the Frechet Distance.\n","    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n","    and X_2 ~ N(mu_2, C_2) is\n","            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n","            \n","    Stable version by Dougal J. Sutherland.\n","    Params:\n","    -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n","             inception net ( like returned by the function 'get_predictions')\n","             for generated samples.\n","    -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n","               on an representive data set.\n","    -- sigma1: The covariance matrix over activations of the pool_3 layer for\n","               generated samples.\n","    -- sigma2: The covariance matrix over activations of the pool_3 layer,\n","               precalcualted on an representive data set.\n","    Returns:\n","    --   : The Frechet Distance.\n","    \"\"\"\n","\n","    mu1 = np.atleast_1d(mu1)\n","    mu2 = np.atleast_1d(mu2)\n","\n","    sigma1 = np.atleast_2d(sigma1)\n","    sigma2 = np.atleast_2d(sigma2)\n","\n","    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n","    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n","\n","    diff = mu1 - mu2\n","\n","    # product might be almost singular\n","    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n","    if not np.isfinite(covmean).all():\n","        msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n","        warnings.warn(msg)\n","        offset = np.eye(sigma1.shape[0]) * eps\n","        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n","\n","    # numerical error might give slight imaginary component\n","    if np.iscomplexobj(covmean):\n","        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n","            m = np.max(np.abs(covmean.imag))\n","            raise ValueError(\"Imaginary component {}\".format(m))\n","        covmean = covmean.real\n","\n","    tr_covmean = np.trace(covmean)\n","\n","    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n","#-------------------------------------------------------------------------------\n","\n","\n","def check_or_download_inception(inception_path):\n","    ''' Checks if the path to the inception file is valid, or downloads\n","        the file if it is not present. '''\n","    INCEPTION_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n","    if inception_path is None:\n","        inception_path = '/tmp'\n","    inception_path = pathlib.Path(inception_path)\n","    model_file = inception_path / 'classify_image_graph_def.pb'\n","    if not model_file.exists():\n","        print(\"Downloading Inception model\")\n","        from urllib import request\n","        import tarfile\n","        fn, _ = request.urlretrieve(INCEPTION_URL)\n","        with tarfile.open(fn, mode='r') as f:\n","            f.extract('classify_image_graph_def.pb', str(model_file.parent))\n","    return str(model_file)\n","#-------------------------------------------------------------------------------\n","\n","\n","######################\n","# ## ADAPTED CODE ## #\n","######################\n","\n","# we adapt the original FID code to be compatible with memory-efficient sequential numpy files\n","\n","def calculate_activation_statistics(path, sess, verbose=False):\n","\n","    act = np.zeros((0, 2048))\n","\n","    # get activations across batches\n","    p = Path(path)\n","    with p.open('rb') as f:\n","        fsz = os.fstat(f.fileno()).st_size\n","        i = 0\n","        while f.tell() < fsz:\n","            if i == 0 or (i+1) % 50 == 0:\n","                print('Batch {}'.format(i+1))\n","            image_batch = np.load(f)\n","            act_batch = get_activations(image_batch, sess, image_batch.shape[0], verbose)\n","            act = np.concatenate((act, act_batch), 0)\n","            i += 1\n","\n","    # get mean and covariance of activations and return\n","    mu = np.mean(act, axis=0)\n","    sigma = np.cov(act, rowvar=False)\n","    return mu, sigma\n","\n","def calculate_fid(path1, path2, inception_path):\n","    inception_path = check_or_download_inception(inception_path)\n","\n","    with tf.device(\"/gpu:0\"):\n","        create_inception_graph(str(inception_path))\n","\n","    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n","        sess.run(tf.global_variables_initializer())\n","        m1, s1 = calculate_activation_statistics(path1, sess)\n","        m2, s2 = calculate_activation_statistics(path2, sess)\n","        fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n","        return fid_value\n","\n","\n","# run experiment\n","fid_value = calculate_fid(config['path_1'], config['path_2'], None)\n","print(\"FID: \", fid_value)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPHJse+0rZ46I0l9WOXzayy","collapsed_sections":[],"name":"fid_orig.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
